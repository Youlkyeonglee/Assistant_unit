{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function, division\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import os\n",
    "import time\n",
    "\n",
    "import Augmentor\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "train_size:  50000 \n",
      "test_size :  10000\n",
      "('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
      "len class:  10\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "p = Augmentor.Pipeline()\n",
    "p.random_erasing(0.5,0.4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop((32, 32), padding=4),   #left, top, right, bottom\n",
    "    p.torch_transform(),\n",
    "#     p.sample(10000),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='/home/lee/Research/3.place_lbp_prediction_ISIE2019/Residual_Attention_Network/create_attention_model/data/',\n",
    "                               train=True,\n",
    "                               transform=train_transform,\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='/home/lee/Research/3.place_lbp_prediction_ISIE2019/Residual_Attention_Network/create_attention_model/data/',\n",
    "                              train=False,\n",
    "                              transform=test_transform)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, # 64\n",
    "                                           shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'test' : test_loader    \n",
    "}\n",
    "image_datasets = {\n",
    "    'train': train_dataset,\n",
    "    'test' : test_dataset\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train': len(image_datasets['train']),\n",
    "    'test' : len(image_datasets['test'])\n",
    "}\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "print('train_size: ',dataset_sizes['train'],'\\ntest_size : ',dataset_sizes['test'])\n",
    "print(classes)\n",
    "print('len class: ', len(classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs1, classes = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8daea5b7b8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images1 = inputs1[0].numpy()\n",
    "print(images1.shape)\n",
    "images1 = np.transpose(images1,[1,2,0])\n",
    "print(images1.shape)\n",
    "# plt.subplot(121)\n",
    "plt.imshow(images1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResidualUnit_cifar import ResidualBlock\n",
    "from ASPP_cifar import ASPP_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_cifar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_cifar, self).__init__()\n",
    "        self.begin_residual_blocks = nn.Sequential(\n",
    "            nn.Conv2d(3,64,kernel_size=3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding = 1)\n",
    "        )#16x16\n",
    "        self.trunk_first_conv = nn.Sequential(\n",
    "            nn.Conv2d(64,64, kernel_size=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )#16x16\n",
    "        self.trunk = nn.Sequential(\n",
    "            ResidualBlock(64, 256, 1),\n",
    "            ResidualBlock(256, 256, 1)\n",
    "        )#56x56\n",
    "        self.trunk_last_conv = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2)            \n",
    "        )#56x56\n",
    "        self.trunk_residual = nn.Sequential(\n",
    "            nn.Conv2d(64,256,1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "#             nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1)\n",
    "        )\n",
    "#         resnet = ResNet18()\n",
    "#         self.num_classes = len(class_names)\n",
    "#         self.resnet = nn.Sequential(*list(resnet.children())[:-2])#8x8\n",
    "\n",
    "        self.aspp = ASPP_cifar()\n",
    "        self.mask_first_conv = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, kernel_size=1, stride = 2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )#8x8\n",
    "\n",
    "        self.classconv = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.Conv2d(1024, 2048, kernel_size=1),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.MaxPool2d(2)\n",
    "        )#8x8\n",
    "        self.thresholds = nn.Threshold(0.6, 0.05)\n",
    "        self.mpool = nn.AvgPool2d(kernel_size=8, stride=1)\n",
    "        # y =  x    if x >= threshold\n",
    "        #  value    if x <  threshold\n",
    "        # threshold = 0.1\n",
    "        # value = 20\n",
    "        self.fc = nn.Linear(2048,10)\n",
    "    def forward(self, x):\n",
    "        h = int(x.size()[2] / 2)\n",
    "        w = int(x.size()[3] / 2)\n",
    "        x1 = self.begin_residual_blocks(x)#16x16\n",
    "#         print(x1.shape)\n",
    "#         print(x1.shape)\n",
    "#################trunk_part#################\n",
    "        out_trunk1 = self.trunk_first_conv(x1)#16x16\n",
    "        out_trunk2 = self.trunk(out_trunk1)#16x16\n",
    "        out_trunk3 = self.trunk_last_conv(out_trunk2)#16x16\n",
    "#         out_trunk = F.upsample(out_trunk, size=(h,w), mode=\"bilinear\")#16x16x256\n",
    "        out_trunk4 = out_trunk3 + self.trunk_residual(x1)#16x16\n",
    "        out_trunk4 = F.softmax(out_trunk4)\n",
    "#################trunk_part#################        \n",
    "\n",
    "#################mask_part#################\n",
    "        feature_map = self.mask_first_conv(x1)#16x16x256\n",
    "        mask1 = self.aspp(feature_map)#8x8x256\n",
    "#         print(mask.shape)\n",
    "        mask2 = F.upsample(mask1, size=(h, w), mode=\"bilinear\") #16x16x256\n",
    "        mask2 = F.softmax(mask2)\n",
    "        mask2 = self.thresholds(mask2)\n",
    "#################mask_part#################\n",
    "        out1 = (1 + mask2) * out_trunk4 #16x16x256\n",
    "        out1 = F.softmax(out1)\n",
    "        out2 = self.classconv(out1)#8x8\n",
    "        out3 = self.mpool(out2)#1x1x512\n",
    "        out4 = out3.view(out3.size(0),-1)\n",
    "        out  = self.fc(out4)\n",
    "\n",
    "        return out, x1, out_trunk1, out_trunk2, out_trunk3, feature_map, mask1, mask2, out1, out2, out3, out4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:         # Conv weight init\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Attention_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA, model\")\n",
    "    model.cuda() #after second other epoch model\n",
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, scheduler, criterion, optimizer, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_test = 0\n",
    "    avg_acc_test = 0\n",
    "    \n",
    "    train_batches = len(train_loader)\n",
    "    test_batches = len(test_loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_test = 0\n",
    "        acc_train = 0\n",
    "        acc_test = 0\n",
    "        \n",
    "        model.train(True)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "            # Use half training dataset\n",
    "            if i >= train_batches / 2:\n",
    "                break\n",
    "            inputs, labels = data            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "            out, x1, out_trunk1, out_trunk2, out_trunk3, feature_map, mask1, mask2, out1, out2, out3, out4 = model(inputs)\n",
    "            _, preds = torch.max(out, 1)\n",
    "            loss = criterion(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item() * inputs.size(0)\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            del inputs, labels, out, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train * 2 / len(train_dataset)\n",
    "        avg_acc = acc_train.double() * 2 / len(train_dataset)\n",
    "        writer.add_scalar('data/train_loss_places', avg_loss, epoch)\n",
    "        writer.add_scalar('data/train_acc_places', avg_acc, epoch)\n",
    "        \n",
    "        \n",
    "        model.train(False)\n",
    "        model.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            if i % 100 == 0:\n",
    "                print()\n",
    "                print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                out, x1, out_trunk1, out_trunk2, out_trunk3, feature_map, mask1, mask2, out1, out2, out3, out4 = model(inputs)\n",
    "                _, preds = torch.max(out, 1)\n",
    "                loss = criterion(out, labels)\n",
    "                loss_test += loss.item() * inputs.size(0)\n",
    "                acc_test += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, out, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_test = loss_test / len(test_dataset)\n",
    "        avg_acc_test = acc_test.double() / len(test_dataset)\n",
    "        writer.add_scalar('data/val_loss_places', avg_loss_test, epoch)\n",
    "        writer.add_scalar('data/val_acc_places', avg_acc_test, epoch)\n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch+1))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        print(\"Avg loss (test): {:.4f}\".format(avg_loss_test))\n",
    "        print(\"Avg acc (test): {:.4f}\".format(avg_acc_test))\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_test > best_acc:\n",
    "            best_acc = avg_acc_test\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "        # Decaying Learning Rate\n",
    "        if (epoch+1) / float(total_epoch) == 0.3 or (epoch+1) / float(total_epoch) == 0.6 or (epoch+1) / float(total_epoch) == 0.9:\n",
    "            lr /= 10\n",
    "            print('reset learning rate to:', lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "                print(param_group['lr'])\n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f} at {}\".format(best_acc, best_epoch+1))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "lr = 0.001  # 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "total_epoch = 150\n",
    "model_train = train_model(model, scheduler, criterion, optimizer, num_epochs=total_epoch)\n",
    "torch.save(model_train.state_dict(), './Trained/cifar_10_adam_0322.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################train more\n",
    "model_train = Attention_cifar()\n",
    " # load the pre-trained weights\n",
    "model_file = 'model_cifar10_small_2_softmax_attention.pt'\n",
    "path = '/home/lee/Research/3.place_lbp_prediction_ISIE2019/Residual_Attention_Network/create_attention_model/small_3/Trained/' + model_file\n",
    "model_train.load_state_dict(torch.load(path))\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA, model_trian\")\n",
    "    model_train.cuda() #after second other epoch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "lr = 0.0001  # 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "total_epoch = 400\n",
    "model_train = train_model(model, criterion, optimizer, lr, num_epochs=total_epoch)\n",
    "torch.save(model.state_dict(), './Trained/model_cifar10_small_3_trainmore_softmax_attention.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
